{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import librosa\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'down',\n",
       " 'eight',\n",
       " 'five',\n",
       " 'four',\n",
       " 'go',\n",
       " 'happy',\n",
       " 'house',\n",
       " 'left',\n",
       " 'marvin',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'off',\n",
       " 'on',\n",
       " 'one',\n",
       " 'right',\n",
       " 'seven',\n",
       " 'sheila',\n",
       " 'six',\n",
       " 'stop',\n",
       " 'three',\n",
       " 'tree',\n",
       " 'two',\n",
       " 'up',\n",
       " 'wow',\n",
       " 'yes',\n",
       " 'zero']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_folder_path= 'C:\\\\Users\\\\junsu\\\\Downloads\\\\audio'\n",
    "list_word_folder= os.listdir(audio_folder_path)[1:]\n",
    "list_word_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 11167863134238981988]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### bird end ###\n",
      "### cat end ###\n",
      "### dog end ###\n",
      "### down end ###\n",
      "### eight end ###\n",
      "### five end ###\n",
      "### four end ###\n",
      "### go end ###\n",
      "### happy end ###\n",
      "### house end ###\n",
      "### left end ###\n",
      "### marvin end ###\n",
      "### nine end ###\n",
      "### no end ###\n",
      "### off end ###\n",
      "### on end ###\n",
      "### one end ###\n",
      "### right end ###\n",
      "### seven end ###\n",
      "### sheila end ###\n",
      "### six end ###\n",
      "### stop end ###\n",
      "### three end ###\n",
      "### tree end ###\n",
      "### two end ###\n",
      "### up end ###\n",
      "### wow end ###\n",
      "### yes end ###\n",
      "### zero end ###\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "Y= np.array([])\n",
    "ver_speaker='012c8324' # 임의의 화자\n",
    "\n",
    "for word in list_word_folder:\n",
    "    word_path= audio_folder_path+'/'+word\n",
    "    file_list= os.listdir(word_path) # wav 파일\n",
    "    \n",
    "    for file in file_list:\n",
    "        file_path= word_path+'/'+file\n",
    "        \n",
    "        #피처 추출(tensorflow 사용)\n",
    "        wav_loader= tf.io.read_file(file_path)\n",
    "        audio, sr = tf.audio.decode_wav(wav_loader, desired_channels=1,\n",
    "                                    desired_samples= 16000 ) # sample rate= 16000으로 설정\n",
    "        waveform= tf.squeeze(audio, axis=-1)\n",
    "        \n",
    "        #stft로 스펙트로그램 값 저장 (short time fourier transform)\n",
    "        spectrogram= tf.signal.stft(waveform, frame_length= 128,\n",
    "                                   frame_step=128)\n",
    "        \n",
    "        # 차원이 맞지 않는 데이터는 삭제\n",
    "        if spectrogram.shape==(125, 65):\n",
    "            X.append(spectrogram)\n",
    "            speaker= file[:8]\n",
    "            if speaker==ver_speaker:\n",
    "                Y= np.append(Y, 0)\n",
    "            else:\n",
    "                Y= np.append(Y, 1)\n",
    "        else:\n",
    "            pass\n",
    "    print(f'### {word} end ###')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63008, 125, 65)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63008,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "## 0.6: 0.2: 0.2 로 분리\n",
    "## Stratifiy를 이용해서 데이터 불균형 해소\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, Y, test_size= 0.4, stratify= Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37804, 125, 65) (37804,)\n",
      "(25204, 125, 65) (25204,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val= train_test_split(X_test, y_test, test_size=0.5, stratify= y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cnn 을 위해 차원 확장\n",
    "train_X= np.expand_dims(X_train, -1)\n",
    "val_X=np.expand_dims(X_val,-1)\n",
    "test_X= np.expand_dims(X_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 311s 261ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 303s 256ms/step - loss: 1.0315e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 266s 225ms/step - loss: 1.6745e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 240s 203ms/step - loss: 4.4709e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 1.9903e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 223s 189ms/step - loss: 5.4217e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 223s 189ms/step - loss: 1.4342e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 9.5721e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 224s 189ms/step - loss: 6.4664e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 5.2276e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 5.4784e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 223s 189ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 223s 189ms/step - loss: 2.6167e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 223s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 223s 189ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 224s 190ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 4.6260e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1182/1182 [==============================] - 223s 189ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1182/1182 [==============================] - 224s 189ms/step - loss: 3.0016e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1182/1182 [==============================] - 224s 190ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 3.4935e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1182/1182 [==============================] - 221s 187ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 1.6012e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1182/1182 [==============================] - 221s 187ms/step - loss: 8.5359e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 3.5836e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1182/1182 [==============================] - 221s 187ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1182/1182 [==============================] - 221s 187ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1182/1182 [==============================] - 223s 189ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1182/1182 [==============================] - 221s 187ms/step - loss: 2.1803e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 1.5989e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1182/1182 [==============================] - 221s 187ms/step - loss: 2.3223e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1182/1182 [==============================] - 221s 187ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1182/1182 [==============================] - 223s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 1.0353e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1182/1182 [==============================] - 222s 187ms/step - loss: 7.8236e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1182/1182 [==============================] - 221s 187ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 6.9971e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1182/1182 [==============================] - 222s 188ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1182/1182 [==============================] - 221s 187ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 00051: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "\n",
    "\n",
    "#Define Model\n",
    "model = models.Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(125, 65,1)))\n",
    "model.add(MaxPooling2D(pool_size= (2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# callback\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "\n",
    "history = model.fit(train_X,\n",
    "                    y_train,\n",
    "                    validation_data=(val_X, y_val),\n",
    "                    callbacks=[es],\n",
    "                    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 63, 64)       640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 61, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 59, 29, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 29, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 29, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12992)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                415776    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 434,946\n",
      "Trainable params: 434,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 23s 59ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "## Evaluate\n",
    "\n",
    "test_loss, test_mae= model.evaluate(test_X, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
